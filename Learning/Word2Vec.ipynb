{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54881e16-5e97-4755-8099-6241781166bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3.3\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "print(gensim.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87dde12f-e899-4393-aaf1-29d28eb00350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping completed!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_path = \"/Users/twinklemittal/Desktop/AI/Machine_learning/machine_learning_algorithms/Learning_Dataset/GoogleNews-vectors-negative300.bin.zip\"\n",
    "extract_path = \"/Users/twinklemittal/Desktop/AI/Machine_learning/machine_learning_algorithms/Learning_Dataset/\"  # Directory where it will be extracted\n",
    "\n",
    "# Extract the ZIP file\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"Unzipping completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a9bad83-4ac6-4b0c-9fe8-59e35ca0b147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "\n",
      "Most similar words to 'king':\n",
      "kings: 0.7138046622276306\n",
      "queen: 0.6510956287384033\n",
      "monarch: 0.6413194537162781\n",
      "crown_prince: 0.6204219460487366\n",
      "prince: 0.6159993410110474\n",
      "sultan: 0.5864824056625366\n",
      "ruler: 0.5797566771507263\n",
      "princes: 0.5646552443504333\n",
      "Prince_Paras: 0.5432944297790527\n",
      "throne: 0.5422105193138123\n",
      "\n",
      "Word analogy: king - man + woman = ?\n",
      "Answer: queen with similarity 0.7118192911148071\n",
      "\n",
      "Cosine similarity between 'king' and 'queen': 0.6510956287384033\n",
      "\n",
      "Vector representation of the word 'king':\n",
      "[ 1.25976562e-01  2.97851562e-02  8.60595703e-03  1.39648438e-01\n",
      " -2.56347656e-02 -3.61328125e-02  1.11816406e-01 -1.98242188e-01\n",
      "  5.12695312e-02  3.63281250e-01 -2.42187500e-01 -3.02734375e-01\n",
      " -1.77734375e-01 -2.49023438e-02 -1.67968750e-01 -1.69921875e-01\n",
      "  3.46679688e-02  5.21850586e-03  4.63867188e-02  1.28906250e-01\n",
      "  1.36718750e-01  1.12792969e-01  5.95703125e-02  1.36718750e-01\n",
      "  1.01074219e-01 -1.76757812e-01 -2.51953125e-01  5.98144531e-02\n",
      "  3.41796875e-01 -3.11279297e-02  1.04492188e-01  6.17675781e-02\n",
      "  1.24511719e-01  4.00390625e-01 -3.22265625e-01  8.39843750e-02\n",
      "  3.90625000e-02  5.85937500e-03  7.03125000e-02  1.72851562e-01\n",
      "  1.38671875e-01 -2.31445312e-01  2.83203125e-01  1.42578125e-01\n",
      "  3.41796875e-01 -2.39257812e-02 -1.09863281e-01  3.32031250e-02\n",
      " -5.46875000e-02  1.53198242e-02 -1.62109375e-01  1.58203125e-01\n",
      " -2.59765625e-01  2.01416016e-02 -1.63085938e-01  1.35803223e-03\n",
      " -1.44531250e-01 -5.68847656e-02  4.29687500e-02 -2.46582031e-02\n",
      "  1.85546875e-01  4.47265625e-01  9.58251953e-03  1.31835938e-01\n",
      "  9.86328125e-02 -1.85546875e-01 -1.00097656e-01 -1.33789062e-01\n",
      " -1.25000000e-01  2.83203125e-01  1.23046875e-01  5.32226562e-02\n",
      " -1.77734375e-01  8.59375000e-02 -2.18505859e-02  2.05078125e-02\n",
      " -1.39648438e-01  2.51464844e-02  1.38671875e-01 -1.05468750e-01\n",
      "  1.38671875e-01  8.88671875e-02 -7.51953125e-02 -2.13623047e-02\n",
      "  1.72851562e-01  4.63867188e-02 -2.65625000e-01  8.91113281e-03\n",
      "  1.49414062e-01  3.78417969e-02  2.38281250e-01 -1.24511719e-01\n",
      " -2.17773438e-01 -1.81640625e-01  2.97851562e-02  5.71289062e-02\n",
      " -2.89306641e-02  1.24511719e-02  9.66796875e-02 -2.31445312e-01\n",
      "  5.81054688e-02  6.68945312e-02  7.08007812e-02 -3.08593750e-01\n",
      " -2.14843750e-01  1.45507812e-01 -4.27734375e-01 -9.39941406e-03\n",
      "  1.54296875e-01 -7.66601562e-02  2.89062500e-01  2.77343750e-01\n",
      " -4.86373901e-04 -1.36718750e-01  3.24218750e-01 -2.46093750e-01\n",
      " -3.03649902e-03 -2.11914062e-01  1.25000000e-01  2.69531250e-01\n",
      "  2.04101562e-01  8.25195312e-02 -2.01171875e-01 -1.60156250e-01\n",
      " -3.78417969e-02 -1.20117188e-01  1.15234375e-01 -4.10156250e-02\n",
      " -3.95507812e-02 -8.98437500e-02  6.34765625e-03  2.03125000e-01\n",
      "  1.86523438e-01  2.73437500e-01  6.29882812e-02  1.41601562e-01\n",
      " -9.81445312e-02  1.38671875e-01  1.82617188e-01  1.73828125e-01\n",
      "  1.73828125e-01 -2.37304688e-01  1.78710938e-01  6.34765625e-02\n",
      "  2.36328125e-01 -2.08984375e-01  8.74023438e-02 -1.66015625e-01\n",
      " -7.91015625e-02  2.43164062e-01 -8.88671875e-02  1.26953125e-01\n",
      " -2.16796875e-01 -1.73828125e-01 -3.59375000e-01 -8.25195312e-02\n",
      " -6.49414062e-02  5.07812500e-02  1.35742188e-01 -7.47070312e-02\n",
      " -1.64062500e-01  1.15356445e-02  4.45312500e-01 -2.15820312e-01\n",
      " -1.11328125e-01 -1.92382812e-01  1.70898438e-01 -1.25000000e-01\n",
      "  2.65502930e-03  1.92382812e-01 -1.74804688e-01  1.39648438e-01\n",
      "  2.92968750e-01  1.13281250e-01  5.95703125e-02 -6.39648438e-02\n",
      "  9.96093750e-02 -2.72216797e-02  1.96533203e-02  4.27246094e-02\n",
      " -2.46093750e-01  6.39648438e-02 -2.25585938e-01 -1.68945312e-01\n",
      "  2.89916992e-03  8.20312500e-02  3.41796875e-01  4.32128906e-02\n",
      "  1.32812500e-01  1.42578125e-01  7.61718750e-02  5.98144531e-02\n",
      " -1.19140625e-01  2.74658203e-03 -6.29882812e-02 -2.72216797e-02\n",
      " -4.82177734e-03 -8.20312500e-02 -2.49023438e-02 -4.00390625e-01\n",
      " -1.06933594e-01  4.24804688e-02  7.76367188e-02 -1.16699219e-01\n",
      "  7.37304688e-02 -9.22851562e-02  1.07910156e-01  1.58203125e-01\n",
      "  4.24804688e-02  1.26953125e-01  3.61328125e-02  2.67578125e-01\n",
      " -1.01074219e-01 -3.02734375e-01 -5.76171875e-02  5.05371094e-02\n",
      "  5.26428223e-04 -2.07031250e-01 -1.38671875e-01 -8.97216797e-03\n",
      " -2.78320312e-02 -1.41601562e-01  2.07031250e-01 -1.58203125e-01\n",
      "  1.27929688e-01  1.49414062e-01 -2.24609375e-02 -8.44726562e-02\n",
      "  1.22558594e-01  2.15820312e-01 -2.13867188e-01 -3.12500000e-01\n",
      " -3.73046875e-01  4.08935547e-03  1.07421875e-01  1.06933594e-01\n",
      "  7.32421875e-02  8.97216797e-03 -3.88183594e-02 -1.29882812e-01\n",
      "  1.49414062e-01 -2.14843750e-01 -1.83868408e-03  9.91210938e-02\n",
      "  1.57226562e-01 -1.14257812e-01 -2.05078125e-01  9.91210938e-02\n",
      "  3.69140625e-01 -1.97265625e-01  3.54003906e-02  1.09375000e-01\n",
      "  1.31835938e-01  1.66992188e-01  2.35351562e-01  1.04980469e-01\n",
      " -4.96093750e-01 -1.64062500e-01 -1.56250000e-01 -5.22460938e-02\n",
      "  1.03027344e-01  2.43164062e-01 -1.88476562e-01  5.07812500e-02\n",
      " -9.37500000e-02 -6.68945312e-02  2.27050781e-02  7.61718750e-02\n",
      "  2.89062500e-01  3.10546875e-01 -5.37109375e-02  2.28515625e-01\n",
      "  2.51464844e-02  6.78710938e-02 -1.21093750e-01 -2.15820312e-01\n",
      " -2.73437500e-01 -3.07617188e-02 -3.37890625e-01  1.53320312e-01\n",
      "  2.33398438e-01 -2.08007812e-01  3.73046875e-01  8.20312500e-02\n",
      "  2.51953125e-01 -7.61718750e-02 -4.66308594e-02 -2.23388672e-02\n",
      "  2.99072266e-02 -5.93261719e-02 -4.66918945e-03 -2.44140625e-01\n",
      " -2.09960938e-01 -2.87109375e-01 -4.54101562e-02 -1.77734375e-01\n",
      " -2.79296875e-01 -8.59375000e-02  9.13085938e-02  2.51953125e-01]\n",
      "\n",
      "Odd one out in the set ['man', 'woman', 'king', 'apple']: apple\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "# Load the pretrained Word2Vec model (in binary format)\n",
    "model_path = '/Users/twinklemittal/Desktop/AI/Machine_learning/machine_learning_algorithms/Learning_Dataset/GoogleNews-vectors-negative300.bin'  # Replace with the actual path to the Word2Vec model file\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "\n",
    "# Check if the model is loaded properly\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Example of finding the most similar words to a given word\n",
    "word = \"king\"\n",
    "print(f\"\\nMost similar words to '{word}':\")\n",
    "similar_words = model.most_similar(word, topn=10)\n",
    "for similar_word, similarity in similar_words:\n",
    "    print(f\"{similar_word}: {similarity}\")\n",
    "\n",
    "# Example of word analogy: \"king is to queen as man is to woman\"\n",
    "print(\"\\nWord analogy: king - man + woman = ?\")\n",
    "result = model.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"], topn=1)\n",
    "print(f\"Answer: {result[0][0]} with similarity {result[0][1]}\")\n",
    "\n",
    "# Example of finding word similarity\n",
    "word1, word2 = \"king\", \"queen\"\n",
    "similarity = model.similarity(word1, word2)\n",
    "print(f\"\\nCosine similarity between '{word1}' and '{word2}': {similarity}\")\n",
    "\n",
    "# Example of finding the vector representation of a word\n",
    "word_vector = model['king']\n",
    "\n",
    "print(f\"\\nVector representation of the word 'king':\\n{word_vector}\")\n",
    "\n",
    "# Example of finding words that don't match in a set of words (odd one out)\n",
    "odd_one_out = model.doesnt_match([\"man\", \"woman\", \"king\", \"apple\"])\n",
    "print(f\"\\nOdd one out in the set ['man', 'woman', 'king', 'apple']: {odd_one_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f01ffcb-c715-43cd-bfba-a15df46794bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_one_out = model.doesnt_match([\"cpp\", \"java\", \"dance\", \"javascript\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36d14c15-a26c-47cf-8cec-513004e27538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dance\n"
     ]
    }
   ],
   "source": [
    "print(odd_one_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d8d3285-c8ca-47fc-b2fe-d504aeeff194",
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_one_out = model.doesnt_match([\"pant\", \"shirt\", \"saree\", \"shocks\", \"pen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e50d86e-f011-4784-ab07-b1188068e5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shocks\n"
     ]
    }
   ],
   "source": [
    "print(odd_one_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b92367db-8032-43fa-adec-f4cb1250f4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06445312 -0.16015625 -0.01208496  0.13476562 -0.22949219  0.16210938\n",
      "  0.3046875  -0.1796875  -0.12109375  0.25390625 -0.01428223 -0.06396484\n",
      " -0.08056641 -0.05688477 -0.19628906  0.2890625  -0.05151367  0.14257812\n",
      " -0.10498047 -0.04736328 -0.34765625  0.35742188  0.265625    0.00188446\n",
      " -0.01586914  0.00195312 -0.35546875  0.22167969  0.05761719  0.15917969\n",
      "  0.08691406 -0.0267334  -0.04785156  0.23925781 -0.05981445  0.0378418\n",
      "  0.17382812 -0.41796875  0.2890625   0.32617188  0.02429199 -0.01647949\n",
      " -0.06494141 -0.08886719  0.07666016 -0.15136719  0.05249023 -0.04199219\n",
      " -0.05419922  0.00108337 -0.20117188  0.12304688  0.09228516  0.10449219\n",
      " -0.00408936 -0.04199219  0.01409912 -0.02111816 -0.13476562 -0.24316406\n",
      "  0.16015625 -0.06689453 -0.08984375 -0.07177734 -0.00595093 -0.00482178\n",
      " -0.00089264 -0.30664062 -0.0625      0.07958984 -0.00909424 -0.04492188\n",
      "  0.09960938 -0.33398438 -0.3984375   0.05541992 -0.06689453 -0.04467773\n",
      "  0.11767578 -0.13964844 -0.26367188  0.17480469 -0.17382812 -0.40625\n",
      " -0.06738281 -0.07617188  0.09423828  0.20996094 -0.16308594 -0.08691406\n",
      " -0.0534668  -0.10351562 -0.07617188 -0.11083984 -0.03515625 -0.14941406\n",
      "  0.0378418   0.38671875  0.14160156 -0.2890625  -0.16894531 -0.140625\n",
      " -0.04174805  0.22753906  0.24023438 -0.01599121 -0.06787109  0.21875\n",
      " -0.42382812 -0.5625     -0.49414062 -0.3359375   0.13378906  0.01141357\n",
      "  0.13671875  0.0324707   0.06835938 -0.27539062 -0.15917969  0.00121307\n",
      "  0.01208496 -0.0039978   0.00442505 -0.04541016  0.08642578  0.09960938\n",
      " -0.04296875 -0.11328125  0.13867188  0.41796875 -0.28320312 -0.07373047\n",
      " -0.11425781  0.08691406 -0.02148438  0.328125   -0.07373047 -0.01348877\n",
      "  0.17773438 -0.02624512  0.13378906 -0.11132812 -0.12792969 -0.12792969\n",
      "  0.18945312 -0.13867188  0.29882812 -0.07714844 -0.37695312 -0.10351562\n",
      "  0.16992188 -0.10742188 -0.29882812  0.00866699 -0.27734375 -0.20996094\n",
      " -0.1796875  -0.19628906 -0.22167969  0.08886719 -0.27734375 -0.13964844\n",
      "  0.15917969  0.03637695  0.03320312 -0.08105469  0.25390625 -0.08691406\n",
      " -0.21289062 -0.18945312 -0.22363281  0.06542969 -0.16601562  0.08837891\n",
      " -0.359375   -0.09863281  0.35546875 -0.00741577  0.19042969  0.16992188\n",
      " -0.06005859 -0.20605469  0.08105469  0.12988281 -0.01135254  0.33203125\n",
      " -0.08691406  0.27539062 -0.03271484  0.12011719 -0.0625      0.1953125\n",
      " -0.10986328 -0.11767578  0.20996094  0.19921875  0.02954102 -0.16015625\n",
      "  0.00276184 -0.01367188  0.03442383 -0.19335938  0.00352478 -0.06542969\n",
      " -0.05566406  0.09423828  0.29296875  0.04052734 -0.09326172 -0.10107422\n",
      " -0.27539062  0.04394531 -0.07275391  0.13867188  0.02380371  0.13085938\n",
      "  0.00236511 -0.2265625   0.34765625  0.13574219  0.05224609  0.18164062\n",
      "  0.0402832   0.23730469 -0.16992188  0.10058594  0.03833008  0.10839844\n",
      " -0.05615234 -0.00946045  0.14550781 -0.30078125 -0.32226562  0.18847656\n",
      " -0.40234375 -0.3125     -0.08007812 -0.26757812  0.16699219  0.07324219\n",
      "  0.06347656  0.06591797  0.17285156 -0.17773438  0.00276184 -0.05761719\n",
      " -0.2265625  -0.19628906  0.09667969  0.13769531 -0.49414062 -0.27929688\n",
      "  0.12304688 -0.30078125  0.01293945 -0.1875     -0.20898438 -0.1796875\n",
      " -0.16015625 -0.03295898  0.00976562  0.25390625 -0.25195312  0.00210571\n",
      "  0.04296875  0.01184082 -0.20605469  0.24804688 -0.203125   -0.17773438\n",
      "  0.07275391  0.04541016  0.21679688 -0.2109375   0.14550781 -0.16210938\n",
      "  0.20410156 -0.19628906 -0.35742188  0.35742188 -0.11962891  0.35742188\n",
      "  0.10351562  0.07080078 -0.24707031 -0.10449219 -0.19238281  0.1484375\n",
      "  0.00057983  0.296875   -0.12695312 -0.03979492  0.13183594 -0.16601562\n",
      "  0.125       0.05126953 -0.14941406  0.13671875 -0.02075195  0.34375   ]\n"
     ]
    }
   ],
   "source": [
    "word_vector = model['apple']\n",
    "print(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3ffa16d-98c9-45f3-8be8-5ad9275ef028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(word_vector.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "97c26210-e3d9-42f8-a59d-e0b983549cf3",
   "metadata": {},
   "source": [
    "How to use this pretrained word2vec model in the keras and tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28d09ea2-51e2-481a-9190-46a29b28d503",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2vec_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense, GlobalAveragePooling1D\n\u001b[32m      6\u001b[39m embedding_dim = \u001b[32m300\u001b[39m \u001b[38;5;66;03m# Google Word2Vec model has 300 dimersions\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m vocab_size = \u001b[38;5;28mlen\u001b[39m(\u001b[43mword2vec_model\u001b[49m.key_to_index) \u001b[38;5;66;03m# Total number of words in vocabulary\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Initialize embedding matrix with zeros\u001b[39;00m\n\u001b[32m     10\u001b[39m embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
      "\u001b[31mNameError\u001b[39m: name 'word2vec_model' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling1D\n",
    "\n",
    "embedding_dim = 300 # Google Word2Vec model has 300 dimersions\n",
    "vocab_size = len(word2vec_model.key_to_index) # Total number of words in vocabulary\n",
    "\n",
    "# Initialize embedding matrix with zeros\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "# Create a mapping from words to their corresponding vectors\n",
    "word_index = {} # This will store {word: index} mapping\n",
    "\n",
    "for i,word in enumerate(word2vec_model.key_to_index.keys()):\n",
    "    embedding_matrix[i] = word2vec_model[word]\n",
    "    word_index[word] = i # Assign index to each word\n",
    "print(\"Embedding matrix created!\")\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=vocab_size,  # size of vocabulary\n",
    "    output_dim= embedding_dim, # word vector dimensions (300)\n",
    "    weights=[embedding_matrix], # load pertrained word2vec weights\n",
    "    input_length=20, # Length of input sequence (adjust as needed)\n",
    "    trainable=False # set to False to freeze the pretrained embeddings\n",
    ")\n",
    "print(\"Embedding layer created!\")\n",
    "\n",
    "# Define a simple model\n",
    "model = Sequential([\n",
    "    embedding_layer, # Pretrained Word2vec embeddings\n",
    "    GlobalAveragePooling1D(), # Averages word vectors\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid') # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc885425-d926-4700-bc4b-26ca168f02b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embedding matrix: (3000000, 300)\n",
      "float32\n",
      "Embedding matrix shape: (3000000, 300)\n"
     ]
    }
   ],
   "source": [
    "# Get the full weight matrix (each row corresponds to a word vector)\n",
    "import numpy as np\n",
    "\n",
    "embedding_weights = model.vectors\n",
    "\n",
    "print(\"Shape of embedding matrix:\", embedding_weights.shape)\n",
    "print(embedding_weights.dtype)\n",
    "\n",
    "\n",
    "# Convert the entire weight matrix to NumPy(copy of the above weights so we dont modify the original ones)\n",
    "embedding_matrix = np.array(embedding_weights)\n",
    "\n",
    "print(\"Embedding matrix shape:\", embedding_matrix.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3a1ca-0f39-4622-a762-9047a61ecb20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (nlp312)",
   "language": "python",
   "name": "nlp312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
