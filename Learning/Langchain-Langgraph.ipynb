{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f694cc20-a26c-42cd-9322-a34e57254885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting langchain[groq]\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain[groq])\n",
      "  Downloading langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain[groq])\n",
      "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain[groq])\n",
      "  Downloading langsmith-0.4.21-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain[groq])\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain[groq])\n",
      "  Downloading sqlalchemy-2.0.43-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from langchain[groq]) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from langchain[groq]) (6.0.2)\n",
      "Collecting langchain-groq (from langchain[groq])\n",
      "  Downloading langchain_groq-0.3.7-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.72->langchain[groq])\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain[groq])\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain[groq]) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain[groq]) (25.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain[groq])\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain[groq])\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain[groq])\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain[groq])\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from requests<3,>=2->langchain[groq]) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from requests<3,>=2->langchain[groq]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from requests<3,>=2->langchain[groq]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from requests<3,>=2->langchain[groq]) (2025.8.3)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith>=0.1.17->langchain[groq])\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.1.17->langchain[groq])\n",
      "  Downloading orjson-3.11.3-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain[groq])\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain[groq])\n",
      "  Downloading zstandard-0.24.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.1 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[groq])\n",
      "  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[groq])\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[groq])\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[groq])\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting groq<1,>=0.30.0 (from langchain-groq->langchain[groq])\n",
      "  Downloading groq-0.31.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting distro<2,>=1.7.0 (from groq<1,>=0.30.0->langchain-groq->langchain[groq])\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.75-py3-none-any.whl (443 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sqlalchemy-2.0.43-cp312-cp312-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading langsmith-0.4.21-py3-none-any.whl (378 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading orjson-3.11.3-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (238 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.24.0-cp312-cp312-macosx_11_0_arm64.whl (640 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m640.3/640.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading langchain_groq-0.3.7-py3-none-any.whl (16 kB)\n",
      "Downloading groq-0.31.0-py3-none-any.whl (131 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: zstandard, typing-inspection, tenacity, SQLAlchemy, sniffio, python-dotenv, pydantic-core, orjson, jsonpointer, h11, distro, annotated-types, requests-toolbelt, pydantic, jsonpatch, httpcore, anyio, httpx, langsmith, groq, langchain-core, langchain-text-splitters, langchain-groq, langchain\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24/24\u001b[0m [langchain]24\u001b[0m [langchain]core]\n",
      "\u001b[1A\u001b[2KSuccessfully installed SQLAlchemy-2.0.43 annotated-types-0.7.0 anyio-4.10.0 distro-1.9.0 groq-0.31.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.27 langchain-core-0.3.75 langchain-groq-0.3.7 langchain-text-splitters-0.3.11 langsmith-0.4.21 orjson-3.11.3 pydantic-2.11.7 pydantic-core-2.33.2 python-dotenv-1.1.1 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 typing-inspection-0.4.1 zstandard-0.24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"langchain[groq]\" python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f636e917-bf3a-453f-8339-8c104cd9b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55217547-7535-45a0-8d98-988e681e97e6",
   "metadata": {},
   "source": [
    "Turn on LangSmith Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56f464e3-2116-458a-83f7-18ab3f03f6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"smithkey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83777416-3749-488d-9239-0376e6d20673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"qwen/qwen3-32b\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c15ca5b-a8bc-4747-a08e-6382462d048e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, so I need to explain neural networks. Hmm, neural networks are a type of machine learning model inspired by the human brain, right? Let me start by recalling what I know.\\n\\nFirst, they consist of layers of interconnected nodes, or neurons, which process information. There\\'s an input layer, one or more hidden layers, and an output layer. Each neuron in a layer is connected to neurons in the next layer. These connections have weights that determine the strength of the signal passed along them.\\n\\nWait, how do they actually work? I think each neuron takes an input, which is a combination of the outputs from the previous layer multiplied by their respective weights. Then there\\'s a bias term, and they apply an activation function to produce the neuron\\'s output. The activation function introduces non-linearity, allowing the network to learn complex patterns.\\n\\nCommon activation functions include ReLU (Rectified Linear Unit), which is max(0, x), and sigmoid, which squashes the input between 0 and 1. The choice of activation can affect the network\\'s performance and training speed.\\n\\nTraining a neural network involves adjusting the weights and biases to minimize a loss function, which measures how well the network is performing. This is usually done using optimization algorithms like gradient descent. The process of adjusting the weights is called backpropagation, where the error is propagated backward through the network to update the weights.\\n\\nWait, backpropagation uses the chain rule of calculus to compute the gradients of the loss with respect to each weight. Then, the weights are updated in the direction that reduces the loss. This is an iterative process, often done with multiple epochs, where the network sees the training data multiple times.\\n\\nNeural networks can be used for various tasks like classification, regression, image recognition, natural language processing, etc. Convolutional Neural Networks (CNNs) are specialized for grid-like data such as images, and they use convolutional layers to automatically and adaptively learn spatial hierarchies of features.\\n\\nRecurrent Neural Networks (RNNs) are designed for sequential data, like time series or text, where the order of data points matters. They have loops that allow information to persist, but traditional RNNs can have issues with vanishing or exploding gradients. Long Short-Term Memory (LSTM) networks and Gated Recurrent Units (GRUs) are variants that address these issues.\\n\\nI should mention that neural networks have hyperparameters like the number of layers, the number of neurons per layer, the learning rate, batch size, and others. These need to be tuned for optimal performance.\\n\\nOverfitting is a common problem where the model performs well on training data but poorly on unseen data. Techniques to prevent overfitting include regularization (like L2 regularization or dropout), using more training data, and early stopping.\\n\\nLet me check if I\\'m missing anything. Oh, maybe mention different types of neural networks, like feedforward networks, which are the basic type, and others like autoencoders for unsupervised learning. Also, the concept of deep learning refers to neural networks with many layers, enabling the model to learn hierarchical representations of data.\\n\\nAnother point is the importance of data in training neural networks. They require large amounts of data to generalize well. Data preprocessing steps like normalization and data augmentation are also crucial.\\n\\nI should explain the training process step by step to make it clearer. Start with input data, forward propagation to compute the output, calculate the loss, backpropagation to compute gradients, and then update weights using an optimizer.\\n\\nMaybe use an example to illustrate, like a simple neural network for classifying handwritten digits (MNIST dataset). But since the user asked for an explanation, not an example, maybe keep it general.\\n\\nAlso, mention that neural networks are part of a broader field called deep learning. They have achieved state-of-the-art results in many domains because of their ability to model complex patterns.\\n\\nWait, what about the components of a neural network? Input layer receives the data, hidden layers perform transformations, and output layer produces the prediction. Each connection between neurons has a weight, and each neuron has a bias. The activation function introduces non-linearity.\\n\\nI need to make sure the explanation is clear and not too technical. Avoid jargon where possible, but some terms are necessary. Maybe start with a simple definition, then break down the components and how they work together.\\n\\nLet me outline the structure:\\n\\n1. Introduction to neural networks and their inspiration from the brain.\\n2. Basic structure: layers, neurons, weights, biases, activation functions.\\n3. How data flows through the network (forward propagation).\\n4. Training the network: loss function, optimization, backpropagation.\\n5. Different types of neural networks (CNNs, RNNs, etc.).\\n6. Key considerations: hyperparameters, overfitting, data requirements.\\n7. Applications and importance in AI.\\n\\nThis should cover the main points. Now, check for any inaccuracies. For example, the role of the activation function is crucial for non-linearities. Without them, the network would just be a linear model regardless of the number of layers. Also, backpropagation is the algorithm used to compute gradients, not the optimization itself‚Äîoptimization refers to the process of using gradients to update weights, often via gradient descent.\\n\\nMake sure to mention that neural networks are universal approximators, meaning they can approximate any function given sufficient capacity, but this is a theoretical result and practical training can be challenging.\\n\\nOkay, I think that covers the essentials. Now, organize the thoughts into a coherent explanation without being too verbose.\\n</think>\\n\\nNeural networks are computational models inspired by the structure and function of the human brain. They are a cornerstone of modern machine learning, enabling computers to learn patterns and make decisions from data. Here\\'s a structured breakdown of their key aspects:\\n\\n---\\n\\n### **1. Basic Structure**\\n- **Layers**: Neural networks consist of **input**, **hidden**, and **output** layers.\\n  - **Input Layer**: Receives raw data (e.g., pixels in an image).\\n  - **Hidden Layers**: Intermediate layers that transform input data into meaningful representations (features). A network can have one or multiple hidden layers.\\n  - **Output Layer**: Produces the final prediction (e.g., class probabilities in classification).\\n- **Neurons (Nodes)**: Each neuron in a layer is connected to neurons in the next layer via **weights** (learnable parameters). Weights determine the strength of the signal passed between neurons.\\n- **Bias**: An additional parameter added to each neuron to adjust the output independently of inputs.\\n\\n---\\n\\n### **2. How Data Flows (Forward Propagation)**\\n1. **Input Data**: Data is fed into the input layer.\\n2. **Weighted Sum**: Each neuron computes a weighted sum of its inputs plus a bias.\\n3. **Activation Function**: Applies a non-linear transformation to the weighted sum. Common functions include:\\n   - **ReLU**: $ f(x) = \\\\max(0, x) $ (popular for hidden layers).\\n   - **Sigmoid**: $ f(x) = \\\\frac{1}{1+e^{-x}} $ (squashes input to [0,1], often used in binary classification).\\n   - **Softmax**: Converts outputs into probabilities for multi-class classification.\\n4. **Output**: The processed data flows through layers until it reaches the output layer.\\n\\n---\\n\\n### **3. Training the Network**\\nNeural networks learn by adjusting their weights and biases to minimize a **loss function** (e.g., mean squared error for regression, cross-entropy for classification). This is achieved via:\\n\\n#### **a. Optimization Algorithms**\\n- **Gradient Descent**: Iteratively updates weights in the direction that reduces loss.\\n  - **Learning Rate**: Controls the size of weight updates (too high = unstable, too low = slow convergence).\\n  - Variants: Stochastic Gradient Descent (SGD), Adam, RMSProp.\\n\\n#### **b. Backpropagation**\\n- Computes gradients of the loss with respect to each weight using the **chain rule** of calculus.\\n- Propagates errors backward from the output layer to adjust weights and biases.\\n\\n#### **c. Training Process**\\n1. **Forward Pass**: Compute predictions using current weights.\\n2. **Loss Calculation**: Measure discrepancy between predictions and true labels.\\n3. **Backward Pass**: Compute gradients via backpropagation.\\n4. **Weight Update**: Adjust weights using an optimizer.\\n\\n---\\n\\n### **4. Variants of Neural Networks**\\n- **Feedforward Neural Networks (FNNs)**: Basic type with unidirectional data flow (no loops).\\n- **Convolutional Neural Networks (CNNs)**: Specialized for grid-like data (images, videos). Use **convolutional layers** to automatically learn spatial hierarchies of features (e.g., edges ‚Üí textures ‚Üí objects).\\n- **Recurrent Neural Networks (RNNs)**: Designed for sequential data (text, time series). Maintain memory of past inputs via loops. Variants like **LSTMs** and **GRUs** address vanishing gradient issues.\\n- **Transformers**: Use self-attention mechanisms to process sequences more efficiently (e.g., BERT, GPT in NLP).\\n\\n---\\n\\n### **5. Key Considerations**\\n- **Hyperparameters**: Tuneable settings like number of layers, neurons, learning rate, and batch size.\\n- **Overfitting**: When a model performs well on training data but poorly on new data. Mitigation techniques:\\n  - **Regularization**: L2 (weight decay), dropout.\\n  - **Data Augmentation**: Increases training data diversity.\\n  - **Early Stopping**: Halts training when validation performance plateaus.\\n- **Data Requirements**: Neural networks thrive on large, diverse datasets. Preprocessing (normalization, augmentation) is critical.\\n\\n---\\n\\n### **6. Applications**\\n- **Computer Vision**: Image classification, object detection (CNNs).\\n- **Natural Language Processing**: Sentiment analysis, machine translation (Transformers).\\n- **Reinforcement Learning**: Game playing (AlphaGo), robotics.\\n- **Healthcare**: Medical imaging, drug discovery.\\n\\n---\\n\\n### **7. Why Neural Networks Work Well**\\n- **Non-linearities**: Activation functions enable modeling complex, non-linear patterns.\\n- **Hierarchical Learning**: Hidden layers learn features at different abstraction levels (e.g., edges ‚Üí shapes ‚Üí objects).\\n- **Universality**: Theoretical results (e.g., Universal Approximation Theorem) show they can approximate any function given sufficient capacity.\\n\\n---\\n\\n### **Example: Classifying Handwritten Digits (MNIST)**\\n1. **Input**: 28x28 pixel image (784 inputs).\\n2. **Hidden Layers**: Two layers with 128 neurons each and ReLU activations.\\n3. **Output**: 10 neurons with softmax activation (probabilities for digits 0‚Äì9).\\n4. **Training**: Use CNNs or FNNs with cross-entropy loss and Adam optimizer.\\n\\n---\\n\\n### **Challenges**\\n- **Computational Cost**: Training deep networks requires GPUs/TPUs.\\n- **Interpretability**: \"Black-box\" nature; difficult to explain decisions.\\n- **Data Dependency**: Requires large, high-quality datasets.\\n\\n---\\n\\nNeural networks form the foundation of **deep learning**, a field that has revolutionized AI by enabling machines to achieve human-like performance in tasks like image recognition, language understanding, and autonomous driving. Their success hinges on combining mathematical rigor (calculus, linear algebra) with engineering insights (hyperparameter tuning, architectures).'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(\"Explain me about neural networks\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7474a4bc-7d4d-45ab-a886-59b49eaef002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, I need to figure out who the current Prime Minister of India is. Let me start by recalling some recent Indian politics. I remember that India is a parliamentary democracy, so the Prime Minister is the head of government. The country's Prime Minister is usually the leader of the majority party in the Lok Sabha, the lower house of Parliament.\\n\\nAs of my last update, the Prime Minister was Narendra Modi. He has been in office since 2014, right? His party, the Bharatiya Janata Party (BJP), has been quite influential. But I should check if there have been any changes since then. Let me think about any recent elections. The 2019 general election might have been a re-election for Modi, and the next general election is expected in 2024. So unless there was a snap election or a significant political shift, he should still be in power.\\n\\nI should also consider if there's been any interim or acting Prime Minister. For example, sometimes when a Prime Minister resigns or passes away, there might be an interim leader until elections. But I don't recall any such events in India recently. Another angle: look at the current President of India. The President is Droupadi Murmu, who took office in July 2022. The President and Prime Minister are different roles; the President is the ceremonial head, while the Prime Minister is the head of government. So that doesn't affect the answer.\\n\\nAlso, I can think about recent events. If there was a major political scandal or a significant event that led to a change in leadership, that might be a factor. But again, nothing comes to mind. The BJP has been dominant, and Modi has been re-elected in 2019 with a strong mandate. Unless there's a leadership change within the party, which I'm not aware of, Modi should still be the Prime Minister.\\n\\nWait, but I need to confirm the exact timeline. The term of the Prime Minister is five years, unless there's a vote of no confidence. The 2014 election put Modi in, then 2019 re-elected him. The next election is 2024. So as of now, 2023, he should still be serving. I don't think there's been any resignation or removal. Therefore, the current Prime Minister of India is Narendra Modi. I should double-check this to ensure I'm not missing any recent news, but given the context of when this question was asked, and my knowledge cutoff in October 2023, I can confidently say it's Modi.\\n</think>\\n\\nAs of October 2023, the **Prime Minister of India is Narendra Modi**. He has served in this role since May 26, 2014, and was re-elected in the 2019 general election. Modi leads the **Bharatiya Janata Party (BJP)**, which holds a majority in the Lok Sabha (India's lower house of Parliament). His current term is expected to last until the next general election, tentatively scheduled for 2024. \\n\\nFor the most up-to-date information, always verify with recent news or official government sources.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(\"Who is the prime minister of India\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "569c1f9e-dff3-4600-92e3-6f4f8d421198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user just said \"Hello\". I should respond in a friendly and welcoming manner. Let me make sure to acknowledge their greeting and offer assistance. Maybe something like, \"Hello! How can I assist you today?\" That\\'s open-ended and invites them to ask questions or share what they need help with. I should keep it simple and approachable. No need for any markdown formatting here. Just a straightforward, warm response.\\n</think>\\n\\nHello! How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 101, 'prompt_tokens': 9, 'total_tokens': 110, 'completion_time': 1.144355966, 'prompt_time': 0.006333582, 'queue_time': 0.043520488, 'total_time': 1.150689548}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--121e9fdb-a10c-4589-aa04-548dd61c51a8-0', usage_metadata={'input_tokens': 9, 'output_tokens': 101, 'total_tokens': 110})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "model.invoke(\"Hello\")\n",
    "\n",
    "model.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])\n",
    "\n",
    "model.invoke([HumanMessage(\"Hello\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a02b1bd-c62c-4466-a9cc-df7cba8e685c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user is asking for a single-word name of a place to travel in India. Let me think about the different regions and their famous spots. First, I need to consider iconic destinations. Varanasi comes to mind because it\\'s a holy city on the Ganges and known for its ghats. Then there\\'s Kerala, which is a state with beautiful backwaters and beaches. Jaipur is famous for its forts and palaces, being the capital of Rajasthan. Goa is a popular beach destination with colonial architecture. Ladakh is a high-altitude area with stunning landscapes. Rishikesh is another spiritual place, known for yoga and the Ganges. Kerala again is good for houseboat tours. Darjeeling in West Bengal is famous for tea plantations. Udaipur is known as the Venice of the East with its lakes. Hampi in Karnataka is a UNESCO site with historical ruins. Which one is the most iconic and can be represented as a single word without confusion? Maybe \"Ladakh\" because it\\'s unique and offers a distinct experience. Or \"Goa\" for beaches. \"Varanasi\" is also strong. But \"Ladakh\" might have fewer alternatives. Let me check if there are other possibilities. \"Sikkim\" is another option with Gangtok as a capital. Hmm. The user wants one word, so maybe the state or district name. Kerala is a state but also a good choice. Let me go with \"Ladakh\" as it\\'s less common but offers a unique travel experience.\\n</think>\\n\\n**Ladakh**', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 326, 'prompt_tokens': 22, 'total_tokens': 348, 'completion_time': 0.866968785, 'prompt_time': 0.006911092, 'queue_time': 0.067182798, 'total_time': 0.873879877}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--fdee5195-fc93-49cf-ac88-537138e3796c-0', usage_metadata={'input_tokens': 22, 'output_tokens': 326, 'total_tokens': 348})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Suggest me name of a place in one word to travel in India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6a88d4d-b347-4c6c-8f7a-b0d007dde65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "travel_template = \"Suggest me name of a place in one word to travel in {country}\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([(\"system\", travel_template), (\"user\", \"{country}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60c8c567-1666-40a9-8a23-54ac4d2a3595",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.invoke({\"country\": \"India\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c35efa4f-f4f7-4506-813f-943b752c51a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user is asking for a one-word name of a place to travel in India. Let me think. They might want a single word that\\'s easy to remember and represents a popular destination.\\n\\nFirst, I should consider major cities known for tourism. Places like Jaipur, Delhi, Mumbai come to mind. But maybe they want something a bit more unique or less obvious? Let me check some other options.\\n\\nThen there are hill stations like Shimla or Manali. But \"Shimla\" is a single word. Wait, the user wants one word, so \"Shimla\" is good. But maybe they prefer a city known for historical sites? Like Varanasi? That\\'s one word too. \\n\\nAlternatively, \"Goa\" is a state, but it\\'s a single word and a major tourist spot. \"Goa\" is short and catchy. Also, \"Udaipur\" is a beautiful city in Rajasthan. \\n\\nI should also think about natural attractions. \"Kerala\" is a state, but maybe the user wants a city. Hmm. \"Agra\" is one word and home to the Taj Mahal. That\\'s a classic choice. \\n\\nWait, the user might prefer a place that\\'s not just a city. Maybe a hill station like \"Darjeeling\"? That\\'s one word and famous for tea and views. \\n\\nLet me verify if all these are single words. Jaipur, Agra, Shimla, Udaipur, Darjeeling, Goa, Varanasi. Yes, all are single words. \\n\\nWhich one is the best suggestion? It depends on what they\\'re looking for. If they want historical, Agra for Taj Mahal. For spiritual, Varanasi. For beaches, Goa. For hill stations, Shimla or Darjeeling. For royal heritage, Jaipur or Udaipur. \\n\\nSince the user didn\\'t specify, maybe pick one that\\'s versatile. Agra is iconic. Alternatively, Goa is a popular beach destination. Both are strong choices. Let me go with \"Agra\" because it\\'s a single, well-known destination with a major attraction.\\n</think>\\n\\n**Agra** ‚Äì Home to the iconic Taj Mahal, this city in Uttar Pradesh offers a blend of Mughal architecture, rich history, and cultural heritage. A must-visit for travelers seeking grandeur and beauty in one word.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 490, 'prompt_tokens': 28, 'total_tokens': 518, 'completion_time': 3.978538177, 'prompt_time': 0.060952489, 'queue_time': 0.068456371, 'total_time': 4.039490666}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ce2cb8ea-0367-4ed6-b2e2-fc8d9807fa4f-0', usage_metadata={'input_tokens': 28, 'output_tokens': 490, 'total_tokens': 518})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64253a63-33e2-4ace-8d2e-6439151ebfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='Suggest me name of a place in one word to travel in India in month December', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(\"Suggest me name of a place in one word to travel in {country} in month {month}\")\n",
    "prompt = prompt_template.invoke({\"country\": \"India\", \"month\": \"December\"})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92858b55-91b7-49b6-a5cd-e2a68ea9ce18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, the user is asking for a one-word Indian travel destination for December. Let me start by thinking about the best places to visit in India during that month. December in India is winter, so the southern parts like Kerala or Tamil Nadu might be a bit warm, but perhaps the hill stations are more popular. Places like Shimla, Manali, or Mcleodganj come to mind. But the user wants a one-word name. Let me check the options.\\n\\nShimla is a good one-word name. It's a hill station in Himachal Pradesh, and December is when they get snow, so that's a big draw. Manali is another option, but maybe less known as a one-word. Mcleodganj is two words. Then there are the beaches, like Goa, but December is peak season there, but it's still a hot spot. However, Goa is one word. Alternatively, Rajasthan's desert, like Jaisalmer, but December is also good there for festivals. But maybe the user is looking for a more winter-specific destination. \\n\\nHimachal hill stations are a common choice. Then there's Coorg in Karnataka, but December is the rainy season there. Kerala's beaches might be too hot. Maybe Hampi? But that's more of a historical place. Wait, what about Ladakh? December is winter there, but it's very cold, though some people go for the cold desert experience. But Ladakh is one word. \\n\\nAlternatively, maybe a spiritual place like Rishikesh, but December is okay there. However, the main attraction in December might be the snowfall in hill stations. So Shimla is a strong candidate. Let me confirm if there are other one-word hill stations. Maybe Darjeeling, but that's two words. So Shimla is the best bet. Let me make sure there's no other one-word place that's popular in December. Maybe Udaipur? But it's more of a cultural destination. So I think Shimla is the best answer here.\\n</think>\\n\\n**Shimla**\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bf2d2a0-2c98-456e-a124-d772ce466be8",
   "metadata": {},
   "source": [
    "Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ef9bf7a-856f-4c46-a08e-3378801af0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "travel_destination_chain = prompt_template | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9737bced-5b2c-4ec4-8e13-3da362eb11d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user is asking for a single-word name of a place in India to visit in December. Let me start by recalling where in India is good during December. December is winter, so maybe hill stations are a good option because the weather is pleasant there. Places like Shimla, Manali, or maybe McLeod Ganj come to mind. But the user wants just one word, so I need to pick the most popular one that\\'s commonly recommended for December.\\n\\nShimla is a classic hill station, known for its colonial architecture and cold weather. Manali is also popular but maybe a bit more associated with skiing in January. McLeod Ganj is in Himachal Pradesh, close to Dalai Lama\\'s temple, and it\\'s beautiful in winter. Then there\\'s Nainital, another hill station in Uttarakhand. But Shimla might be the most straightforward answer because it\\'s well-known and often suggested for December. Alternatively, maybe Goa if someone wants a beach destination, but December is the start of the winter, so Goa\\'s weather is good then too. But the user might prefer a hill station for a different experience. \\n\\nWait, the user specified \"one word,\" so I need to make sure the place\\'s name is one word. Shimla, Manali, McLeod Ganj (but that\\'s two words), Nainital, Gulmarg. Gulmarg is in Jammu and Kashmir, which is also a good winter destination for skiing. But is it one word? Yes, Gulmarg. However, maybe less known compared to Shimla. \\n\\nAlternatively, maybe Kerala\\'s backwaters in December, but December is the start of the winter there, and it\\'s more for monsoons. No, monsoon season is June to September. December is off-season, so maybe not as crowded. But the weather is still warm. So maybe a beach destination like Goa. But again, Goa is one word. So the options are Shimla, Manali, Nainital, Gulmarg, Goa. \\n\\nWhich is the most commonly suggested? Shimla is a top choice for December. It\\'s in the north, has snow sometimes in January, but December is already cold enough. So I think Shimla is the best one-word answer. Let me double-check if there\\'s any other place. Maybe Leh, but Leh is in Ladakh, and December is very cold there, not sure if it\\'s recommended. Maybe not as much for tourism in December. So sticking with Shimla.\\n</think>\\n\\n**Shimla**'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel_destination_chain.invoke({\"country\": \"India\", \"month\": \"December\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f860d6cf-df24-42de-a540-b17bb34da6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_itinerary_prompt = ChatPromptTemplate.from_template(\"Give me 3 days itinerary for the place {destination}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8b696a3-637f-4a35-8492-5fc45942f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_chain = {\"destination\" : travel_destination_chain} | travel_itinerary_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a666e2c-226b-41d5-9a3c-a0c864422a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, the user wants a 3-day itinerary for Ooty in June. Let me start by recalling the key attractions in Ooty. There are tea plantations, the government botanical garden, Doddabetta Peak, the Rose Garden, and maybe some wildlife like the Ooty Lake or the nearby Nilgiri Biosphere Reserve. \\n\\nFirst, I need to structure the days. Day 1 could be exploring the tea plantations and the botanical garden. Day 2 might focus on the Rose Garden and Doddabetta Peak. Day 3 could include a visit to the Ooty Lake and maybe a local market or wildlife spot.\\n\\nWait, but the user is traveling in June. The monsoon might start there, so I should mention weather advisories, like carrying an umbrella or checking the forecast. Also, some places might have slippery paths or closed due to rain, so suggest alternatives if possible.\\n\\nOn Day 1, starting with the Tea Plantations. The Government Tea Factory is a popular spot. Then the Botanical Garden. Maybe include a visit to the Ooty Lake in the evening? But if it's the start of the monsoon, the lake might be more scenic with mist. \\n\\nDay 2: Rose Garden in the morning. Then Doddabetta Peak. But the peak might be closed during heavy rains. Should I mention that? Maybe suggest an alternative like Sim's Park or the Snake Park if the weather is poor. \\n\\nDay 3: Maybe a trip to the Avalanche Lake or the Chellakurichi Waterfalls. Also, the local market for shopping. But if it's raining, suggest indoor activities like the Ooty Heritage Museum.\\n\\nNeed to balance outdoor and indoor activities in case of rain. Also, note any necessary precautions like wearing comfortable shoes, carrying rain gear, and checking local conditions. \\n\\nTransport: Ooty is accessible by road, rail, and even a narrow-gauge railway. Mentioning that might be helpful. Also, suggest places to stay‚Äîmaybe some cozy cottages or heritage hotels. \\n\\nDining: Include local delicacies like Ooty Kombu and Strawberry treats. \\n\\nMake sure the itinerary is flexible for weather and offers options. Keep the tone friendly and helpful, focusing on the unique aspects of visiting in June. Highlight the monsoon magic with mist and lush greenery as an added attraction. \\n\\nDouble-check the opening times for each attraction and if any require prior booking. Mention that some trails might be slippery, so caution is needed. \\n\\nAlright, structuring the 3 days with a mix of nature, culture, and relaxation, while keeping the weather in mind. That should cover it.\\n</think>\\n\\nHere‚Äôs a **3-day itinerary for Ooty (Udhagamandalam)** in June, designed to balance outdoor adventures, cultural experiences, and flexibility for monsoon weather:\\n\\n---\\n\\n### **Day 1: Tea Plantations & Botanical Wonders**  \\n**Morning**  \\n- **Tea Plantations & Factory Visit**: Explore the **Government Tea Factory** (10 km from Ooty) to learn about tea processing and enjoy a cup of fresh Nilgiri tea. The surrounding plantations offer misty, photogenic trails.  \\n- **Botanical Garden**: Wander through the **Ooty Botanical Garden** (3 km), home to rare orchids, medicinal plants, and a serene rose garden.  \\n\\n**Afternoon**  \\n- **Ooty Lake**: Take a boat ride on the lake or stroll around its perimeter. In June, the monsoon mist adds a magical touch to the view.  \\n\\n**Evening**  \\n- **Sim‚Äôs Park**: Visit this 19th-century park for a peaceful evening walk and stunning views of the Nilgiri hills.  \\n\\n**Tip**: If it rains, visit the **Ooty Heritage Museum** (closed on Mondays) to explore the region‚Äôs colonial history.  \\n\\n---\\n\\n### **Day 2: Peaks, Gardens & Wildlife**  \\n**Morning**  \\n- **Doddabetta Peak**: Hike or take a jeep to the highest point in Ooty (2,637 m). The peak often shrouded in clouds, offering panoramic views. If closed due to rain, substitute with **Chellakurichi Waterfalls** (15 km).  \\n\\n**Afternoon**  \\n- **Rose Garden**: Stroll through the **Nilgiri Rose Garden** (12 km), India‚Äôs largest rose garden, bursting with 160+ varieties.  \\n\\n**Evening**  \\n- **Wildlife Exploration**: Visit the **Nilgiri Biosphere Reserve** (10 km) for a chance to spot tigers and bison (closed at night). Alternatively, enjoy a cup of coffee at a local caf√© in the heart of Ooty.  \\n\\n**Tip**: Pack waterproof gear‚ÄîJune rains can be sudden!  \\n\\n---\\n\\n### **Day 3: Leisure & Local Culture**  \\n**Morning**  \\n- **Avalanche Lake**: Hike or drive to this serene alpine lake (17 km), surrounded by deodar forests and waterfalls.  \\n\\n**Afternoon**  \\n- **Local Market**: Shop for **Nilgiri Hill Organic Coffee**, handwoven shawls, and spices at the **Ooty Market** (12 km).  \\n\\n**Evening**  \\n- **Sunset at Ooty Lake**: End your trip with a quiet sunset view at the lake or enjoy a farewell cup of tea at a hilltop caf√©.  \\n\\n**Optional**: If time allows, visit **Snake Park & Zoological Garden** (16 km) for a relaxed afternoon.  \\n\\n---\\n\\n### **Practical Tips for June Travel**  \\n- **Weather**: June is monsoon season‚Äîcarry an umbrella and waterproof shoes.  \\n- **Packing**: Lightweight clothing, a raincoat, and sturdy hiking boots.  \\n- **Transport**: Hire a local guide for hikes (they know safe paths during rain).  \\n- **Stay**: Opt for cozy hillside cottages or heritage hotels like **The Grand Ooty**.  \\n\\nOoty‚Äôs lush, monsoon-dappled landscapes in June are a hidden gem‚Äîperfect for nature lovers! üåøüåßÔ∏è\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composed_chain.invoke({\"country\": \"India\", \"month\": \"June\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef97cbe0-84f8-4a6d-984a-81cb62842815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\nOkay, so the user is asking who the Prime Minister of India is. Let me start by recalling the current political situation in India. As of my last update in July 2024, Narendra Modi has been serving as the Prime Minister since 2014. He was re-elected in 2019, and there were rumors about a potential third term in 2024, but I don't have specific information on the 2024 election results yet. \\n\\nFirst, I need to confirm if there were any elections in 2024. The Indian general elections are typically held every five years, so the next one after 2019 would be 2024. If elections took place in 2024, the outcome would determine the current Prime Minister. However, since my knowledge is cut off in July 2024, I might not have the latest election results. \\n\\nI should check if there's any information about the 2024 election. From what I know, the Indian National Congress and the BJP were the main competitors. The BJP, led by Modi, has been dominant in recent elections. If they won the 2024 election, Modi would be re-elected. If not, the leadership of the Congress or another party might take over. But without specific data on the 2024 election results, I can't be certain.\\n\\nAnother angle is to consider if there have been any changes in leadership due to other reasons, like resignation or death. However, there's no public information about Modi resigning or any health issues that would affect his leadership. So it's safe to assume he's still in office unless there's been an unexpected event.\\n\\nAdditionally, I should mention that the Prime Minister of India is the head of government, elected by the majority in the Lok Sabha. The current Prime Minister as of my last update is Narendra Modi of the BJP. If there were an election in 2024 and the BJP won, he would continue; if they lost, the new party's leader would take over. \\n\\nI should also note the duration of his tenure. He first became Prime Minister in 2014, re-elected in 2019, and if re-elected in 2024, he would be serving a third term. This is significant because he's one of the longest-serving Prime Ministers in India's history, which could be an interesting point to mention.\\n\\nTo summarize, the answer would be Narendra Modi, but with a caveat that if the 2024 election results are different, the answer might change. Since the user is asking as of now (assuming the current date is 2023 or 2024), I should check if the elections have happened yet. The Indian elections are usually held in April-May and results announced in May-June. If the current date is July 2024, the elections would have been in April-May 2024, so there should be results by now. However, since my knowledge is up to July 2024, I might not have the exact outcome, but I can infer based on available information. \\n\\nReports after the 2024 election indicated that the BJP, led by Modi, won a majority, securing another term. Therefore, as of July 2024, the Prime Minister remains Narendra Modi. I should present this information clearly, mentioning the 2024 election and the possible continuation of his term.\\n</think>\\n\\nAs of July 2024, the Prime Minister of India is **Narendra Modi**. He has served in this role since May 26, 2014, and was re-elected in the **2019 general elections**. In the **2024 Indian general elections** (held in April‚ÄìMay 2024), Modi and his Bharatiya Janata Party (BJP) secured a decisive majority, leading to his reappointment for a **third term**. His tenure continues to focus on economic reforms, infrastructure development, and national security initiatives. \\n\\n**Key Points:**\\n- **Party:** Bharatiya Janata Party (BJP).\\n- **Tenure:** First elected in 2014, re-elected in 2019, and re-elected in 2024.\\n- **Significance:** Modi is one of India's longest-serving Prime Ministers and has become a central figure in Indian politics.\\n\\nFor the most up-to-date information, always refer to recent news or official government sources.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 955, 'prompt_tokens': 15, 'total_tokens': 970, 'completion_time': 3.553681669, 'prompt_time': 0.584272233, 'queue_time': 0.047091855, 'total_time': 4.137953902}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3a2bcc62-8366-461c-a96f-8e4603431632-0', usage_metadata={'input_tokens': 15, 'output_tokens': 955, 'total_tokens': 970})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"who is the prime minister of India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f873645-c9e0-4aa8-adf7-cd4d66fd9b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nAlright, the user previously asked, \"Can you tell me more about him?\" This is a vague question that lacks specific context. I need to clarify who \"him\" refers to. Given the conversation history, the user might not have mentioned the specific person before, or perhaps they mentioned someone in a previous interaction that I don\\'t have access to. Since each session is independent, I should prompt the user to provide more details.\\n\\nTo respond appropriately, I should ask the user to clarify which person they are referring to. This ensures accurate and helpful information. I\\'ll phrase it in a friendly manner to encourage them to specify the name or context related to the individual they\\'re interested in.\\n</think>\\n\\nOf course! Could you please clarify who \"him\" refers to? Let me know the name or context of the person you\\'re interested in, and I‚Äôll provide detailed information! üòä', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 180, 'prompt_tokens': 16, 'total_tokens': 196, 'completion_time': 2.033869661, 'prompt_time': 0.409374156, 'queue_time': 0.065215173, 'total_time': 2.443243817}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7e501953-b368-489e-9cb2-fa33735f424d-0', usage_metadata={'input_tokens': 16, 'output_tokens': 180, 'total_tokens': 196})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Can you tell me more about him?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79da6f0c-9a70-448a-bda4-465bcf3197c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\nOkay, the user asked for a study topic suggestion. Let me think about how to approach this. First, I need to consider their possible interests and academic level. Since they didn't specify, maybe I should offer a range of topics across different fields.\\n\\nLet me start by categorizing potential areas. Science and technology are always popular. Maybe AI ethics? That's timely and has real-world implications. Renewable energy is another hot topic, especially with climate change. Quantum computing is cutting-edge but might be too advanced for some. \\n\\nWhat about social sciences? Climate change's social impacts could be interesting. Psychology topics like the psychology of decision-making might appeal to others. Economics has topics like the gig economy or inequality. \\n\\nFor creative fields, maybe digital art or storytelling. Technical writing is also a skill that's in demand. If they're into health, studying mental health stigma or nutrition trends. \\n\\nI should balance between practical and theoretical topics. Also, consider interdisciplinary areas like AI in healthcare. Maybe include a few questions to help them narrow down. Wait, the user might not know their exact interest yet. Providing a variety of options with brief descriptions could help them decide. Let me list them out with explanations so they can choose based on their interests.\\n</think>\\n\\nCertainly! Here are a few **study topic suggestions** across different fields, depending on your interests and goals:\\n\\n---\\n\\n### **1. Science & Technology**  \\n**AI Ethics and Bias**  \\n- *Why it‚Äôs compelling*: As AI becomes more integrated into society, understanding its ethical implications (e.g., algorithmic bias, privacy, job displacement) is critical.  \\n- *Starter question*: How can we design AI systems that are fair and transparent?  \\n\\n**Climate-Resilient Agriculture**  \\n- *Why it‚Äôs compelling*: Combating food insecurity in a warming world by studying crop genetics, sustainable farming, or soil health.  \\n- *Starter question*: How can CRISPR technology improve drought-resistant crops?  \\n\\n**Quantum Computing Basics**  \\n- *Why it‚Äôs compelling*: Explore the future of computing and its potential to solve complex problems in cryptography, materials science, or drug discovery.  \\n\\n---\\n\\n### **2. Social Sciences & Humanities**  \\n**The Psychology of Conspiracy Theories**  \\n- *Why it‚Äôs compelling*: Understand why people believe in misinformation and how to combat it in an age of social media.  \\n\\n**Urbanization and Mental Health**  \\n- *Why it‚Äôs compelling*: Study how city living affects stress, loneliness, and mental well-being, especially in fast-growing megacities.  \\n\\n**Cultural Memory in Digital Age**  \\n- *Why it‚Äôs compelling*: How do societies preserve and reinterpret history through digital archives, memes, or virtual museums?  \\n\\n---\\n\\n### **3. Business & Economics**  \\n**The Gig Economy‚Äôs Future**  \\n- *Why it‚Äôs compelling*: Analyze labor rights, income inequality, and the role of platforms like Uber or Fiverr in shaping modern work.  \\n\\n**Circular Economy Models**  \\n- *Why it‚Äôs compelling*: Study systems that minimize waste (e.g., product recycling, sharing economies) to achieve sustainability.  \\n\\n**Cryptocurrency and Central Bank Policies**  \\n- *Why it‚Äôs compelling*: How do nations regulate crypto while balancing innovation and financial stability?  \\n\\n---\\n\\n### **4. Creative & Practical Skills**  \\n**Digital Storytelling for Social Change**  \\n- *Why it‚Äôs compelling*: Learn how documentaries, podcasts, or interactive media can raise awareness about causes like climate action or racial justice.  \\n\\n**User Experience (UX) Design**  \\n- *Why it‚Äôs compelling*: Study how people interact with technology and design intuitive interfaces for apps, websites, or VR.  \\n\\n**Creative Writing: Speculative Fiction**  \\n- *Why it‚Äôs compelling*: Explore dystopian futures, AI societies, or alternate histories to reflect on real-world issues.  \\n\\n---\\n\\n### **5. Health & Biology**  \\n**Neuroplasticity and Learning**  \\n- *Why it‚Äôs compelling*: How does the brain adapt to new experiences, and can this be harnessed for education or rehabilitation?  \\n\\n**Mental Health Stigma in Different Cultures**  \\n- *Why it‚Äôs compelling*: Compare how cultural norms shape attitudes toward therapy, depression, and anxiety.  \\n\\n**Synthetic Biology and Biohacking**  \\n- *Why it‚Äôs compelling*: Study the ethics and potential of engineering living organisms for medicine or environmental solutions.  \\n\\n---\\n\\n### **6. Interdisciplinary Topics**  \\n**AI in Healthcare: Opportunities and Challenges**  \\n- *Why it‚Äôs compelling*: Explore how machine learning improves diagnostics but raises questions about data privacy and access.  \\n\\n**Space Law and Ethics**  \\n- *Why it‚Äôs compelling*: As private companies explore space, what rules govern resource extraction, colonization, or conflict?  \\n\\n**Decolonizing Education Systems**  \\n- *Why it‚Äôs compelling*: How can curricula address historical biases and include marginalized voices?  \\n\\n---\\n\\n### **How to Choose?**  \\nAsk yourself:  \\n- Are you passionate about solving real-world problems?  \\n- Do you prefer theoretical research or practical applications?  \\n- Is there a field you want to pivot into (e.g., tech, policy, art)?  \\n\\nLet me know your interests, and I can refine the suggestions! üöÄ\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1083, 'prompt_tokens': 14, 'total_tokens': 1097, 'completion_time': 3.409128155, 'prompt_time': 0.006367355, 'queue_time': 0.062750335, 'total_time': 3.41549551}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--834d1aa7-ebd8-44cc-9a17-f743f5dd8558-0', usage_metadata={'input_tokens': 14, 'output_tokens': 1083, 'total_tokens': 1097})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"suggest me a topic to study\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11d1eadd-9718-4e65-9aca-fdb54a444abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user just asked, \"can you tell me more about the topic?\" but there\\'s no previous context provided. I need to figure out what topic they\\'re referring to. Since the conversation just started, maybe they mentioned a topic in a previous message that I missed? Wait, looking at the history, the user only sent that one message. Hmm.\\n\\nMaybe the user is testing the system or wants a general overview. But the initial message is too vague. Without knowing the specific topic, I can\\'t provide relevant information. The user might be referring to the previous question they had, but there\\'s nothing to reference. \\n\\nI should respond by asking them to clarify the topic they\\'re interested in. Need to prompt them to provide more details so I can assist better. Make sure the response is polite and helpful. Let me check if there\\'s any other context I might have missed. No, the conversation just started. Alright, the best approach is to request the specific topic they want more information on.\\n</think>\\n\\nOf course! However, I need a bit more information to help you effectively. Could you please clarify or specify the topic you\\'re interested in? For example, are you asking about a particular subject (e.g., science, technology, history), a concept, or something else? Let me know, and I‚Äôll provide a detailed explanation! üòä', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 278, 'prompt_tokens': 17, 'total_tokens': 295, 'completion_time': 0.715571579, 'prompt_time': 0.006933835, 'queue_time': 0.076021455, 'total_time': 0.722505414}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--a4ce087a-39d7-4928-badf-724cf8cb13d2-0', usage_metadata={'input_tokens': 17, 'output_tokens': 278, 'total_tokens': 295})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"can you tell me more about the topic?\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1c9d020-5059-403b-88df-3af1849ff616",
   "metadata": {},
   "source": [
    "LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "215bba01-3dca-4f8b-9117-47e720215e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.6.6-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: langchain-core>=0.1 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from langgraph) (0.3.75)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.2.4-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from langgraph) (2.11.7)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from langgraph) (3.5.0)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.10.0-cp312-cp312-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (43 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
      "Requirement already satisfied: anyio in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n",
      "Requirement already satisfied: certifi in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (0.4.21)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.24.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/twinklemittal/.venvs/nlp312/lib/python3.12/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
      "Downloading langgraph-0.6.6-py3-none-any.whl (153 kB)\n",
      "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
      "Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading langgraph_sdk-0.2.4-py3-none-any.whl (53 kB)\n",
      "Downloading ormsgpack-1.10.0-cp312-cp312-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (376 kB)\n",
      "Installing collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5/5\u001b[0m [langgraph]\n",
      "\u001b[1A\u001b[2KSuccessfully installed langgraph-0.6.6 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.4 ormsgpack-1.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a91517-a3bb-49b6-a711-f492c3d085e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from typing import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a18d6d0-c243-4952-ae20-6f3f046fa7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyState(TypedDict):\n",
    "    x: int\n",
    "    y: int\n",
    "    result: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c182ad6-24a3-427d-b68c-b694dc39e967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 10, 'y': 5, 'result': 30}\n"
     ]
    }
   ],
   "source": [
    "# 2. Define your node functions\n",
    "def func1(state: MyState) -> dict:\n",
    "    x, y = state[\"x\"], state[\"y\"]\n",
    "    return {\"result\": x + y}\n",
    "\n",
    "def func2(state: MyState) -> dict:\n",
    "    return {\"result\": 2 * state[\"result\"]}\n",
    "\n",
    "# 3. Build the graph\n",
    "workflow = StateGraph(state_schema=MyState)\n",
    "\n",
    "workflow.add_node(\"node_1\", func1)\n",
    "workflow.add_node(\"node_2\", func2)\n",
    "\n",
    "workflow.add_edge(\"node_1\", \"node_2\")\n",
    "\n",
    "workflow.set_entry_point(\"node_1\")\n",
    "workflow.set_finish_point(\"node_2\")\n",
    "\n",
    "# 4. Compile it\n",
    "app = workflow.compile()\n",
    "\n",
    "# 5. Run it\n",
    "output = app.invoke({\"x\": 10, \"y\": 5})\n",
    "print(output)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc5bb5b6-4d72-4445-8dd8-d37840acfe91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ab9f7-2d1f-4827-9691-7c49cae3b169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (nlp312)",
   "language": "python",
   "name": "nlp312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
